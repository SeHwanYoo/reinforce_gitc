{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld():\n",
    "\n",
    "    def __init__(self): \n",
    "        self.x = 0 \n",
    "        self.y = 0 \n",
    "\n",
    "    def step(self, a):\n",
    "        if a == 0:\n",
    "            self.move_right() \n",
    "        elif a== 1:\n",
    "            self.move_left()\n",
    "        elif a == 2: \n",
    "            self.move_up() \n",
    "        elif a == 3: \n",
    "            self.move_down() \n",
    "\n",
    "        reward = -1 \n",
    "        done = self.is_done()\n",
    "\n",
    "        return (self.x, self.y), reward, done, _ \n",
    "\n",
    "    def move_right(self): \n",
    "        self.y += 1 \n",
    "        if self.y > 3: \n",
    "            self.y = 3\n",
    "\n",
    "\n",
    "    def move_left(self): \n",
    "        self.y -= 1 \n",
    "\n",
    "        if self.y < 0:\n",
    "            self.y = 0 \n",
    "\n",
    "    def move_up(self): \n",
    "        self.x -= 1\n",
    "\n",
    "        if self.x < 0:\n",
    "            self.x = 0 \n",
    "\n",
    "    def move_down(self): \n",
    "        self.x += 1 \n",
    "\n",
    "        if self.x > 3:\n",
    "            self.x = 3 \n",
    "\n",
    "    def is_done(self):\n",
    "        if self.x == 3 and self.y == 3: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_status(self): \n",
    "        return (self.x, self.y)\n",
    "\n",
    "\n",
    "    def reset(self): \n",
    "        self.x = 0 \n",
    "        self.y = 0 \n",
    "\n",
    "        return (self.x, self.y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass \n",
    "\n",
    "    def select_action(self):\n",
    "        coin = random.random()\n",
    "\n",
    "\n",
    "        if coin < 0.25:\n",
    "            action = 0 \n",
    "        elif coin < 0.5:\n",
    "            action = 1\n",
    "        elif coin < 0.75:\n",
    "            action = 2\n",
    "        else:\n",
    "            action = 3\n",
    "\n",
    "        return action\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    env = GridWorld() \n",
    "    agent = Agent()\n",
    "\n",
    "    data = [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "    gamma = 1.0 \n",
    "    alpha = 0.0001 \n",
    "\n",
    "\n",
    "    for k in tqdm(range(50000)):\n",
    "        done = False\n",
    "\n",
    "        history = [] \n",
    "\n",
    "        while not done: \n",
    "            action = agent.select_action()\n",
    "            (x, y), reward, done, _ = env.step(action) \n",
    "            history.append((x, y, reward))\n",
    "\n",
    "        env.reset() \n",
    "\n",
    "\n",
    "        cum_reward = 0 \n",
    "        for trainsition in history[::-1]:\n",
    "\n",
    "            x, y, reward = trainsition\n",
    "            data[x][y] = data[x][y] + alpha * (cum_reward - data[x][y])\n",
    "            cum_reward = cum_reward + gamma * reward\n",
    "\n",
    "    for row in data: \n",
    "        print(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main1():\n",
    "    env = GridWorld() \n",
    "    agent = Agent()\n",
    "\n",
    "    data = [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "    gamma = 1.0 \n",
    "    alpha = 0.01 # MC 에 비해서 좀 더 큰 값을 사용 \n",
    "\n",
    "\n",
    "    for k in tqdm(range(50000)):\n",
    "        done = False\n",
    "\n",
    "        history = [] \n",
    "\n",
    "        while not done: \n",
    "            x, y = env.get_status() \n",
    "            action = agent.select_action()\n",
    "            (x_prime, y_prime), reward, done, _ = env.step(action) \n",
    "            x_prime, y_prime = env.get_status() \n",
    "\n",
    "            # history.append((x, y, reward))\n",
    "            data[x][y] = data[x][y] + alpha * (reward + gamma * data[x_prime][y_prime] - data[x][y])\n",
    "\n",
    "        env.reset() \n",
    "\n",
    "        # cum_reward = 0 \n",
    "        # for trainsition in history[::-1]:\n",
    "\n",
    "        #     x, y, reward = trainsition\n",
    "        #     data[x][y] = data[x][y] + alpha * (cum_reward - data[x][y])\n",
    "        #     cum_reward = cum_reward + gamma * reward\n",
    "\n",
    "    for row in data: \n",
    "        print(row)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:02<00:00, 22099.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-60.70685564796509, -58.38889462972265, -54.94497321571861, -51.05771847780446]\n",
      "[-57.924402660890486, -55.488558550905715, -50.29234783713271, -43.92195007227481]\n",
      "[-54.36395928823983, -50.020090566103164, -40.88156101787654, -29.720999746579253]\n",
      "[-52.112401619460286, -46.312340872976, -30.659254908343048, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:02<00:00, 18564.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-57.96737424984324, -55.92078372504484, -52.628473319935495, -50.026991581021875]\n",
      "[-55.71671332257319, -52.72818738498409, -48.28401693819212, -43.4950362613445]\n",
      "[-52.55373222958305, -47.46694620694326, -38.694979879635184, -29.486061675564144]\n",
      "[-49.72267933508219, -43.14695629814001, -30.288845609057084, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main1()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddde1e1c6000e1d3034bec6257a8f68bed92c50866ae12a8382b98f1add9b5c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
